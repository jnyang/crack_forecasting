{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook imports the ConvLSTM model from [GeoTorchAI](https://kanchanchy.github.io/geotorchai/index.html) for experimentation. The code for training the ConvLSTM is adapted from [here](https://kanchanchy.github.io/geotorchai/coding_examples.html).\n",
    "\n",
    "See [here](https://kanchanchy.github.io/geotorchai/installation.html) for instructions on how to install GeoTorchAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "from geotorchai.models.grid import ConvLSTM\n",
    "\n",
    "# autoreload modules when code is changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# load ImageFolder.py from scripts folder\n",
    "import sys\n",
    "sys.path.append('../scripts/')\n",
    "from ImageFolder import ImageFolder, ImageDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize device with GPU\n",
    "In order to perform deep learning with GPU, we need to check whether GPU is available at first. We will initialize the device with GPU if it is available. Otherwise, CPU will be used as the default device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device\n",
    "\n",
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define method for calculating three types of errors: MSE, MAE, RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_errors(preds, y_true):\n",
    "    pred_mean = preds[:, 0:2]\n",
    "    diff = y_true - pred_mean\n",
    "\n",
    "    mse = np.mean(diff ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.mean(np.abs(diff))\n",
    "\n",
    "    return mse, mae, rmse\n",
    "                               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define method for calculating validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validation_loss(model, val_generator, criterion, device):\n",
    "    model.eval()\n",
    "    mean_loss = []\n",
    "    for i, sample in enumerate(val_generator):\n",
    "        X_c = sample[\"x_closeness\"].type(torch.FloatTensor).to(device)\n",
    "        X_p = sample[\"x_period\"].type(torch.FloatTensor).to(device)\n",
    "        X_t = sample[\"x_trend\"].type(torch.FloatTensor).to(device)\n",
    "        Y_batch = sample[\"y_data\"].type(torch.FloatTensor).to(device)\n",
    "\n",
    "        outputs = model(X_c, X_p, X_t)\n",
    "        mse= criterion(outputs, Y_batch).item()\n",
    "        mean_loss.append(mse)\n",
    "\n",
    "    mean_loss = np.mean(mean_loss)\n",
    "    return mean_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_closeness = 3\n",
    "len_period = 4\n",
    "len_trend = 4\n",
    "nb_residual_unit = 4\n",
    "\n",
    "map_height, map_width = 21, 12\n",
    "nb_flow = 2\n",
    "nb_area = 81\n",
    "\n",
    "len_history = 5\n",
    "len_predict = 1\n",
    "\n",
    "epoch_nums = 3\n",
    "learning_rate = 0.0002\n",
    "batch_size = 32\n",
    "params = {'batch_size': batch_size, 'shuffle': False, 'drop_last':False, 'num_workers': 0}\n",
    "\n",
    "# Sets the model output directory\n",
    "checkpoint_dir = '../models'\n",
    "model_name = 'convlstm'\n",
    "model_dir = checkpoint_dir + \"/\" + model_name\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# For loading pretrained model if available\n",
    "initial_checkpoint = model_dir + '/model.best.pth'\n",
    "LOAD_INITIAL = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data paths\n",
    "data_root = '../data/Processed Dataset/v2 (uses the new segmentation masks)/FutureGAN_format'\n",
    "train_path = os.path.join(data_root, \"train\")\n",
    "test_path = os.path.join(data_root, \"test\")\n",
    "val_path = os.path.join(data_root, \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ImageFolder(root=train_path, transform=transforms.ToTensor())\n",
    "test = ImageFolder(root=test_path, transform=transforms.ToTensor())\n",
    "val = ImageFolder(root=val_path, transform=transforms.ToTensor())\n",
    "\n",
    "train.set_sequential_representation(history_length=5, predict_length=1)\n",
    "test.set_sequential_representation(history_length=5, predict_length=1)\n",
    "val.set_sequential_representation(history_length=5, predict_length=1)\n",
    "\n",
    "train_generator = DataLoader(ImageDataset(train), **params)\n",
    "test_generator = DataLoader(ImageDataset(test), **params)\n",
    "val_generator = DataLoader(ImageDataset(val), **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoTorchConvLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, num_layers):\n",
    "        super().__init__()\n",
    "        self.lstm = ConvLSTM(input_size, hidden_dim = hidden_dim, num_layers = num_layers)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, _ = self.lstm(input_seq)\n",
    "        return lstm_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define method for initializing model and perform training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModelAndTrain():\n",
    "    device = get_device()\n",
    "\n",
    "    model = GeoTorchConvLSTM(nb_flow, [64, 64, 2], 3)\n",
    "\n",
    "    if LOAD_INITIAL:\n",
    "        model.load_state_dict(torch.load(initial_checkpoint, map_location=lambda storage, loc: storage))\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model.to(device)\n",
    "    loss_fn.to(device)\n",
    "\n",
    "    min_val_loss = None\n",
    "    for e in range(epoch_nums):\n",
    "        for i, sample in enumerate(train_generator):\n",
    "            X_batch = sample[\"X_data\"].type(torch.FloatTensor).to(device)\n",
    "            Y_batch = sample[\"Y_data\"].type(torch.FloatTensor).to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(X_batch)\n",
    "            loss = loss_fn(outputs[:, len_history - 1:len_history, :, :, :], Y_batch)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(e + 1, epoch_nums, loss.item()))\n",
    "\n",
    "        val_loss = get_validation_loss(model, val_generator, loss_fn, device)\n",
    "        print('Mean validation loss:', val_loss)\n",
    "\n",
    "        if min_val_loss == None or val_loss < min_val_loss:\n",
    "            min_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), initial_checkpoint)\n",
    "            print('best model saved!')\n",
    "\n",
    "    model.load_state_dict(torch.load(initial_checkpoint, map_location=lambda storage, loc: storage))\n",
    "    model.eval()\n",
    "    rmse_list = []\n",
    "    mse_list = []\n",
    "    mae_list = []\n",
    "    for i, sample in enumerate(test_generator):\n",
    "        X_batch = sample[\"X_data\"].type(torch.FloatTensor).to(device)\n",
    "        Y_batch = sample[\"Y_data\"].type(torch.FloatTensor).to(device)\n",
    "\n",
    "        outputs = model(X_batch)\n",
    "        mse, mae, rmse = compute_errors(outputs[:, len_history - 1:len_history, :, :, :].cpu().data.numpy(),\n",
    "                                        Y_batch.cpu().data.numpy())\n",
    "\n",
    "        rmse_list.append(rmse)\n",
    "        mse_list.append(mse)\n",
    "        mae_list.append(mae)\n",
    "\n",
    "    rmse = np.mean(rmse_list)\n",
    "    mse = np.mean(mse_list)\n",
    "    mae = np.mean(mae_list)\n",
    "\n",
    "    print(\"\\n************************\")\n",
    "    print(\"Test ConvLSTM model with Crack Dataset:\")\n",
    "    print('Test mse: %.6f mae: %.6f rmse (norm): %.6f' % (\n",
    "    mse, mae, rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call model training and testing from main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [256, 66, 3, 3], expected input[32, 65, 128, 128] to have 66 channels, but got 65 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/jenny/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb Cell 19\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jenny/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jenny/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     createModelAndTrain()\n",
      "\u001b[1;32m/Users/jenny/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb Cell 19\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jenny/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb#X21sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m Y_batch \u001b[39m=\u001b[39m sample[\u001b[39m\"\u001b[39m\u001b[39mY_data\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mFloatTensor)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jenny/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb#X21sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jenny/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb#X21sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(X_batch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jenny/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb#X21sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(outputs[:, len_history \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:len_history, :, :, :], Y_batch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jenny/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb#X21sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# Backward and optimize\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/crack/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/crack/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/Users/jenny/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb Cell 19\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jenny/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, input_seq):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jenny/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     lstm_out, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(input_seq)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jenny/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m lstm_out\n",
      "File \u001b[0;32m~/miniconda3/envs/crack/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/crack/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/crack/lib/python3.8/site-packages/geotorchai/models/grid/conv_lstm.py:75\u001b[0m, in \u001b[0;36mConvLSTM.forward\u001b[0;34m(self, input_tensor, hidden_state)\u001b[0m\n\u001b[1;32m     73\u001b[0m output_inner \u001b[39m=\u001b[39m []\n\u001b[1;32m     74\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(seq_len):\n\u001b[0;32m---> 75\u001b[0m     h, c \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcell_list[layer_idx](input_tensor\u001b[39m=\u001b[39;49mcur_layer_input[:, t, :, :, :], cur_state\u001b[39m=\u001b[39;49m[h, c])\n\u001b[1;32m     76\u001b[0m     output_inner\u001b[39m.\u001b[39mappend(h)\n\u001b[1;32m     78\u001b[0m layer_output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(output_inner, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/crack/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/crack/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/crack/lib/python3.8/site-packages/geotorchai/models/grid/conv_lstm.py:115\u001b[0m, in \u001b[0;36m_ConvLSTMCell.forward\u001b[0;34m(self, input_tensor, cur_state)\u001b[0m\n\u001b[1;32m    111\u001b[0m h_cur, c_cur \u001b[39m=\u001b[39m cur_state\n\u001b[1;32m    113\u001b[0m combined \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([input_tensor, h_cur], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)  \u001b[39m# concatenate along channel axis\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m combined_conv \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv(combined)\n\u001b[1;32m    116\u001b[0m cc_i, cc_f, cc_o, cc_g \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msplit(combined_conv, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_dim, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    117\u001b[0m i \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msigmoid(cc_i)\n",
      "File \u001b[0;32m~/miniconda3/envs/crack/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/crack/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/crack/lib/python3.8/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/miniconda3/envs/crack/lib/python3.8/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    457\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [256, 66, 3, 3], expected input[32, 65, 128, 128] to have 66 channels, but got 65 channels instead"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    createModelAndTrain()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
