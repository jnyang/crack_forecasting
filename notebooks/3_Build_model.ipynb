{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook imports the ConvLSTM model from [GeoTorchAI](https://kanchanchy.github.io/geotorchai/index.html) for experimentation. The code for training the ConvLSTM is adapted from [here](https://kanchanchy.github.io/geotorchai/coding_examples.html).\n",
    "\n",
    "See [here](https://kanchanchy.github.io/geotorchai/installation.html) for instructions on how to install GeoTorchAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "from geotorchai.models.grid import ConvLSTM\n",
    "\n",
    "# autoreload modules when code is changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# load ImageFolder.py from scripts folder\n",
    "import sys\n",
    "sys.path.append('../scripts/')\n",
    "from ImageFolder import ImageFolder, ImageDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize device with GPU\n",
    "In order to perform deep learning with GPU, we need to check whether GPU is available at first. We will initialize the device with GPU if it is available. Otherwise, CPU will be used as the default device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device\n",
    "\n",
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define method for calculating three types of errors: MSE, MAE, RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_errors(preds, y_true):\n",
    "    pred_mean = preds[:, 0:2]\n",
    "    diff = y_true - pred_mean\n",
    "\n",
    "    mse = np.mean(diff ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.mean(np.abs(diff))\n",
    "\n",
    "    return mse, mae, rmse\n",
    "                               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define method for calculating validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validation_loss(model, val_generator, criterion, device):\n",
    "    model.eval()\n",
    "    mean_loss = []\n",
    "    for i, sample in enumerate(val_generator):\n",
    "        X_batch = sample[\"X_data\"].type(torch.FloatTensor).to(device)\n",
    "        Y_batch = sample[\"Y_data\"].type(torch.FloatTensor).to(device)\n",
    "\n",
    "        outputs = model(X_batch)\n",
    "        mse=criterion(outputs, Y_batch).item()\n",
    "        mean_loss.append(mse)\n",
    "\n",
    "    mean_loss = np.mean(mean_loss)\n",
    "    return mean_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoTorchConvLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, num_layers):\n",
    "        super().__init__()\n",
    "        self.lstm = ConvLSTM(input_dim=input_size, \n",
    "                             hidden_dim=hidden_dim, \n",
    "                             num_layers=num_layers)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, _ = self.lstm(input_seq)\n",
    "        return lstm_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 1\n",
    "input_width = 128\n",
    "input_height = 128\n",
    "hidden_layer_sizes = [64, 64, 2]\n",
    "num_layers = len(hidden_layer_sizes)\n",
    "\n",
    "len_history = 5\n",
    "len_predict = 1\n",
    "\n",
    "epoch_nums = 3\n",
    "learning_rate = 0.0002\n",
    "batch_size = 32\n",
    "params = {'batch_size': batch_size, 'shuffle': False, 'drop_last':False, 'num_workers': 0}\n",
    "\n",
    "# Sets the model output directory\n",
    "checkpoint_dir = '../models'\n",
    "model_name = 'convlstm'\n",
    "model_dir = checkpoint_dir + \"/\" + model_name\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# For loading pretrained model if available\n",
    "initial_checkpoint = model_dir + '/model.best.pth'\n",
    "LOAD_INITIAL = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data paths\n",
    "data_root = '../data/Processed Dataset/v2 (uses the new segmentation masks)/FutureGAN_format'\n",
    "train_path = os.path.join(data_root, \"train\")\n",
    "test_path = os.path.join(data_root, \"test\")\n",
    "val_path = os.path.join(data_root, \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ImageFolder(root=train_path, transform=transforms.ToTensor())\n",
    "test = ImageFolder(root=test_path, transform=transforms.ToTensor())\n",
    "val = ImageFolder(root=val_path, transform=transforms.ToTensor())\n",
    "\n",
    "train.set_sequential_representation(history_length=len_history, predict_length=len_predict)\n",
    "test.set_sequential_representation(history_length=len_history, predict_length=len_predict)\n",
    "val.set_sequential_representation(history_length=len_history, predict_length=len_predict)\n",
    "\n",
    "train_generator = DataLoader(ImageDataset(train), **params)\n",
    "test_generator = DataLoader(ImageDataset(test), **params)\n",
    "val_generator = DataLoader(ImageDataset(val), **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define method for initializing model and perform training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModelAndTrain():\n",
    "    device = get_device()\n",
    "\n",
    "    model = GeoTorchConvLSTM(input_dim, hidden_layer_sizes, num_layers)\n",
    "\n",
    "    if LOAD_INITIAL:\n",
    "        model.load_state_dict(torch.load(initial_checkpoint, map_location=lambda storage, loc: storage))\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model.to(device)\n",
    "    loss_fn.to(device)\n",
    "\n",
    "    min_val_loss = None\n",
    "    for e in range(epoch_nums):\n",
    "        for i, sample in enumerate(train_generator):\n",
    "            X_batch = sample[\"X_data\"].type(torch.FloatTensor).to(device)\n",
    "            Y_batch = sample[\"Y_data\"].type(torch.FloatTensor).to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(X_batch)\n",
    "            loss = loss_fn(outputs[:, len_history - 1:len_history, :, :, :], Y_batch)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(e + 1, epoch_nums, loss.item()))\n",
    "\n",
    "        val_loss = get_validation_loss(model, val_generator, loss_fn, device)\n",
    "        print('Mean validation loss:', val_loss)\n",
    "\n",
    "        if min_val_loss == None or val_loss < min_val_loss:\n",
    "            min_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), initial_checkpoint)\n",
    "            print('best model saved!')\n",
    "\n",
    "    model.load_state_dict(torch.load(initial_checkpoint, map_location=lambda storage, loc: storage))\n",
    "    model.eval()\n",
    "    rmse_list = []\n",
    "    mse_list = []\n",
    "    mae_list = []\n",
    "    for i, sample in enumerate(test_generator):\n",
    "        X_batch = sample[\"X_data\"].type(torch.FloatTensor).to(device)\n",
    "        Y_batch = sample[\"Y_data\"].type(torch.FloatTensor).to(device)\n",
    "\n",
    "        outputs = model(X_batch)\n",
    "        mse, mae, rmse = compute_errors(outputs[:, len_history - 1:len_history, :, :, :].cpu().data.numpy(),\n",
    "                                        Y_batch.cpu().data.numpy())\n",
    "\n",
    "        rmse_list.append(rmse)\n",
    "        mse_list.append(mse)\n",
    "        mae_list.append(mae)\n",
    "\n",
    "    rmse = np.mean(rmse_list)\n",
    "    mse = np.mean(mse_list)\n",
    "    mae = np.mean(mae_list)\n",
    "\n",
    "    print(\"\\n************************\")\n",
    "    print(\"Test ConvLSTM model with Crack Dataset:\")\n",
    "    print('Test mse: %.6f mae: %.6f rmse (norm): %.6f' % (\n",
    "    mse, mae, rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call model training and testing from main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jenny/miniconda3/envs/crack/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([32, 1, 1, 128, 128])) that is different to the input size (torch.Size([32, 1, 2, 128, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/jenny/miniconda3/envs/crack/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([15, 1, 1, 128, 128])) that is different to the input size (torch.Size([15, 1, 2, 128, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jenny/miniconda3/envs/crack/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([9, 1, 1, 128, 128])) that is different to the input size (torch.Size([9, 5, 2, 128, 128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean validation loss: 0.01693805307149887\n",
      "best model saved!\n",
      "Epoch [2/3], Loss: 0.0100\n",
      "Mean validation loss: 0.016871917992830276\n",
      "best model saved!\n",
      "Epoch [3/3], Loss: 0.0100\n",
      "Mean validation loss: 0.016804130747914314\n",
      "best model saved!\n",
      "\n",
      "************************\n",
      "Test ConvLSTM model with Crack Dataset:\n",
      "Test mse: 0.014031 mae: 0.038125 rmse (norm): 0.118452\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    createModelAndTrain()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
