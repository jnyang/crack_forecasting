{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook lays out the model training process for ConvLSTM, including loading the data, hyperparameter setting, and customizing the loss function.\n",
    "\n",
    "The ConvLSTM implementation is from [GeoTorchAI](https://kanchanchy.github.io/geotorchai/index.html) for experimentation. The code for training the ConvLSTM is adapted from [here](https://kanchanchy.github.io/geotorchai/coding_examples.html). See [here](https://kanchanchy.github.io/geotorchai/installation.html) for instructions on how to install GeoTorchAI.\n",
    "\n",
    "Refer to `scripts/run.py` for the streamlined code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "from geotorchai.models.grid import ConvLSTM\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# autoreload modules when code is changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# load ImageFolder.py from scripts folder\n",
    "import sys\n",
    "sys.path.append('../scripts/')\n",
    "from image_folder import ImageFolder, ImageDataset\n",
    "from loss_functions import SSIMLoss, PhaseFieldLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize device with GPU\n",
    "In order to perform deep learning with GPU, we need to check whether GPU is available at first. We will initialize the device with GPU if it is available. Otherwise, CPU will be used as the default device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device\n",
    "\n",
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define method for calculating three types of errors: MSE, MAE, RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_errors(preds, y_true):\n",
    "    pred_mean = preds[:, 0:2]\n",
    "    diff = y_true - pred_mean\n",
    "\n",
    "    mse = np.mean(diff ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.mean(np.abs(diff))\n",
    "\n",
    "    return mse, mae, rmse             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define method for calculating validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to use plt to save the model predictions\n",
    "def save_pred_plots(outputs, Y_batch, batch_num, epoch, num_samples):\n",
    "    for i in range(num_samples):\n",
    "        try:\n",
    "            plt.figure(figsize=(8, 4))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.imshow(outputs[i, len_history - 1, 0, :, :].cpu().data.numpy(), cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.title(\"Predicted\")\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.imshow(np.squeeze(Y_batch[i, 0, :, :].cpu().data.numpy()), cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.title(\"Ground Truth\")\n",
    "\n",
    "            # save figure to model_dir\n",
    "            plt.savefig(model_dir + f\"/plots/val_batch_{batch_num}_sample_{i}_{epoch}.png\")\n",
    "            # don't show plot\n",
    "            plt.close()\n",
    "        except:\n",
    "            print(f\"sample {i} failed to plot\")\n",
    "            continue\n",
    "\n",
    "def get_validation_loss(model, val_generator, criterion, device, len_history, e):\n",
    "    model.eval()\n",
    "    mean_loss = []\n",
    "    for i, sample in enumerate(val_generator):\n",
    "        X_batch = sample[\"X_data\"].type(torch.FloatTensor).to(device)\n",
    "        Y_batch = sample[\"Y_data\"].type(torch.FloatTensor).to(device)\n",
    "\n",
    "        outputs = model(X_batch)\n",
    "        if type(criterion) == SSIMLoss:\n",
    "            loss = criterion(outputs[:, len_history - 1:len_history, :, :, :], Y_batch).item()\n",
    "        elif type(criterion) == nn.MSELoss:\n",
    "            loss = criterion(outputs, Y_batch).item()\n",
    "        mean_loss.append(loss)\n",
    "        \n",
    "        if (e + 1) % 10 == 0:\n",
    "            # save outputs to plot later\n",
    "            save_pred_plots(outputs, Y_batch, i, epoch=e+1, num_samples=batch_size)\n",
    "\n",
    "    mean_loss = np.mean(mean_loss)\n",
    "    return mean_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoTorchConvLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, num_layers):\n",
    "        super().__init__()\n",
    "        self.lstm = ConvLSTM(input_dim=input_size, \n",
    "                             hidden_dim=hidden_dim, \n",
    "                             num_layers=num_layers)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, _ = self.lstm(input_seq)\n",
    "        return lstm_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "input_dim = 1\n",
    "input_width = 128\n",
    "input_height = 128\n",
    "hidden_layer_sizes = [256, 256, 1]\n",
    "num_layers = len(hidden_layer_sizes)\n",
    "\n",
    "# sequence lengths\n",
    "len_history = 5\n",
    "len_predict = 1\n",
    "\n",
    "# training parameters\n",
    "epoch_nums = 40\n",
    "learning_rate = 0.002\n",
    "batch_size = 1 #4\n",
    "params = {'batch_size': batch_size, 'shuffle': False, 'drop_last':False, 'num_workers': 2}\n",
    "\n",
    "# Create function that assigns model name to global variable\n",
    "def set_model_name(name, initial_model_dir=None):\n",
    "    global model_name, model_dir, model_checkpoint, initial_checkpoint\n",
    "    model_name = name\n",
    "\n",
    "    # Sets the model output directory\n",
    "    checkpoint_dir = '../models/'\n",
    "    model_name = name\n",
    "    model_dir = checkpoint_dir + model_name\n",
    "    model_checkpoint = model_dir + '/model.best.pth'\n",
    "    model_dir_plots = model_dir + \"/plots\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(model_dir_plots, exist_ok=True)\n",
    "    print(f\"Model directory: {model_dir}\")\n",
    "    print(F\"Model directory for plots: {model_dir_plots}\")\n",
    "\n",
    "    # For loading pretrained model if available\n",
    "    if initial_model_dir != None:\n",
    "        initial_checkpoint = initial_model_dir + '/model.best.pth'\n",
    "        print(f\"Initial model checkpoint directory: {initial_model_dir}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data paths\n",
    "data_root = '../data/cracks_s_nb'\n",
    "train_path = os.path.join(data_root, \"train\")\n",
    "test_path = os.path.join(data_root, \"test\")\n",
    "val_path = os.path.join(data_root, \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ImageFolder(root=train_path, transform=transforms.ToTensor())\n",
    "test = ImageFolder(root=test_path, transform=transforms.ToTensor())\n",
    "val = ImageFolder(root=val_path, transform=transforms.ToTensor())\n",
    "\n",
    "train.set_sequential_representation(history_length=len_history, predict_length=len_predict)\n",
    "test.set_sequential_representation(history_length=len_history, predict_length=len_predict)\n",
    "val.set_sequential_representation(history_length=len_history, predict_length=len_predict)\n",
    "\n",
    "train_generator = DataLoader(ImageDataset(train), **params)\n",
    "test_generator = DataLoader(ImageDataset(test), **params)\n",
    "val_generator = DataLoader(ImageDataset(val), **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 128])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.__getitem__(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir='../data/cracks_s_nb', resize_dim=None):\n",
    "    global input_dim, input_width, input_height\n",
    "    # Set data paths\n",
    "    data_root = data_dir\n",
    "    train_path = os.path.join(data_root, \"train\")\n",
    "    test_path = os.path.join(data_root, \"test\")\n",
    "    val_path = os.path.join(data_root, \"val\")\n",
    "    \n",
    "    train = ImageFolder(root=train_path, transform=transforms.ToTensor(), resize=resize_dim)\n",
    "    test = ImageFolder(root=test_path, transform=transforms.ToTensor(), resize=resize_dim)\n",
    "    val = ImageFolder(root=val_path, transform=transforms.ToTensor(), resize=resize_dim)\n",
    "\n",
    "    train.set_sequential_representation(history_length=len_history, predict_length=len_predict)\n",
    "    test.set_sequential_representation(history_length=len_history, predict_length=len_predict)\n",
    "    val.set_sequential_representation(history_length=len_history, predict_length=len_predict)\n",
    "\n",
    "    train_generator = DataLoader(ImageDataset(train), **params)\n",
    "    test_generator = DataLoader(ImageDataset(test), **params)\n",
    "    val_generator = DataLoader(ImageDataset(val), **params)\n",
    "    \n",
    "    input_dim = train.__getitem__(0).shape[0]\n",
    "    input_width = train.__getitem__(0).shape[1]\n",
    "    input_height = train.__getitem__(0).shape[2]\n",
    "    \n",
    "    return train_generator, test_generator, val_generator\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define method for initializing model and perform training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModelAndTrain(loss_fn, train_generator, test_generator, val_generator, LOAD_INITIAL=False):\n",
    "    device = get_device()\n",
    "\n",
    "    model = GeoTorchConvLSTM(input_dim, hidden_layer_sizes, num_layers)\n",
    "\n",
    "    if LOAD_INITIAL:\n",
    "        model.load_state_dict(torch.load(initial_checkpoint, map_location=lambda storage, loc: storage))\n",
    "\n",
    "    loss_fn = loss_fn\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model.to(device)\n",
    "    loss_fn.to(device)\n",
    "\n",
    "    min_val_loss = None\n",
    "    for e in range(epoch_nums):\n",
    "        for i, sample in enumerate(train_generator):\n",
    "            X_batch = sample[\"X_data\"].type(torch.FloatTensor).to(device)\n",
    "            Y_batch = sample[\"Y_data\"].type(torch.FloatTensor).to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(X_batch)\n",
    "            loss = loss_fn(outputs[:, len_history - 1:len_history, :, :, :], Y_batch)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        val_loss = get_validation_loss(model, val_generator, loss_fn, device, len_history, e)\n",
    "        \n",
    "        print('Epoch [{}/{}], Train Loss: {:.4f}'.format(e + 1, epoch_nums, loss.item()), 'Mean Val Loss:', val_loss)\n",
    "\n",
    "        if min_val_loss == None or val_loss < min_val_loss:\n",
    "            min_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), model_checkpoint)\n",
    "            print('best model saved!')\n",
    "\n",
    "    model.load_state_dict(torch.load(model_checkpoint, map_location=lambda storage, loc: storage))\n",
    "    model.eval()\n",
    "    rmse_list = []\n",
    "    mse_list = []\n",
    "    mae_list = []\n",
    "    for i, sample in enumerate(test_generator):\n",
    "        X_batch = sample[\"X_data\"].type(torch.FloatTensor).to(device)\n",
    "        Y_batch = sample[\"Y_data\"].type(torch.FloatTensor).to(device)\n",
    "\n",
    "        outputs = model(X_batch)\n",
    "        mse, mae, rmse = compute_errors(outputs[:, len_history - 1:len_history, :, :, :].cpu().data.numpy(),\n",
    "                                        Y_batch.cpu().data.numpy())\n",
    "\n",
    "        rmse_list.append(rmse)\n",
    "        mse_list.append(mse)\n",
    "        mae_list.append(mae)\n",
    "        \n",
    "        # save plots\n",
    "        for j in range(batch_size):\n",
    "            try:\n",
    "                plt.figure(figsize=(8, 4))\n",
    "                plt.subplot(1, 2, 1)\n",
    "                plt.imshow(outputs[j, len_history - 1, 0, :, :].cpu().data.numpy(), cmap='gray')\n",
    "                plt.axis('off')\n",
    "                plt.title(\"Predicted\")\n",
    "                plt.subplot(1, 2, 2)\n",
    "                plt.imshow(np.squeeze(Y_batch[j, 0, :, :].cpu().data.numpy()), cmap='gray')\n",
    "                plt.axis('off')\n",
    "                plt.title(\"Ground Truth\")\n",
    "                # save figure to model_dir\n",
    "                plt.savefig(model_dir + f\"/plots/test_batch_{i}_sample_{i}_{epoch_nums}.png\")\n",
    "                # don't show plot\n",
    "                plt.close()\n",
    "            except:\n",
    "                print(f\"sample {j} failed to plot\")\n",
    "                continue\n",
    "\n",
    "    rmse = np.mean(rmse_list)\n",
    "    mse = np.mean(mse_list)\n",
    "    mae = np.mean(mae_list)\n",
    "\n",
    "    print(\"\\n************************\")\n",
    "    print(\"Test ConvLSTM model with Crack Dataset:\")\n",
    "    print('Test mse: %.6f mae: %.6f rmse (norm): %.6f' % (\n",
    "    mse, mae, rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set loss functions\n",
    "loss_mse = nn.MSELoss()\n",
    "loss_ssim = SSIMLoss()\n",
    "loss_phasefield = PhaseFieldLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call model training and testing from main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model directory: ../models/convlstm_mse_epoch40_lr0.002_pretraining\n",
      "Model directory for plots: ../models/convlstm_mse_epoch40_lr0.002_pretraining/plots\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 22.33 GB, other allocations: 13.89 GB, max allowed: 36.27 GB). Tried to allocate 64.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/jy/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb Cell 23\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jy/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb#X30sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     train_generator, test_generator, val_generator \u001b[39m=\u001b[39m load_data(\u001b[39m'\u001b[39m\u001b[39m../data/simple_line\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jy/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb#X30sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     set_model_name(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mconvlstm_mse_epoch\u001b[39m\u001b[39m{\u001b[39;00mepoch_nums\u001b[39m}\u001b[39;00m\u001b[39m_lr\u001b[39m\u001b[39m{\u001b[39;00mlearning_rate\u001b[39m}\u001b[39;00m\u001b[39m_pretraining\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jy/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb#X30sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     createModelAndTrain(loss_mse, train_generator, test_generator, val_generator)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jy/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb#X30sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m# createModelAndTrain(loss_fn=loss_ssim)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jy/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb#X30sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m# createModelAndTrain(loss_fn=loss_phasefield)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jy/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb#X30sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jy/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb#X30sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# Clear the memory\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jy/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb#X30sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n",
      "\u001b[1;32m/Users/jy/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb Cell 23\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jy/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb#X30sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m Y_batch \u001b[39m=\u001b[39m sample[\u001b[39m\"\u001b[39m\u001b[39mY_data\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mFloatTensor)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jy/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb#X30sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jy/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb#X30sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(X_batch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jy/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb#X30sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(outputs[:, len_history \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:len_history, :, :, :], Y_batch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jy/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb#X30sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# Backward and optimize\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/crack_forecasting/.conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/GitHub/crack_forecasting/.conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/Users/jy/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb Cell 23\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jy/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb#X30sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, input_seq):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jy/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb#X30sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     lstm_out, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(input_seq)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jy/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb#X30sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m lstm_out\n",
      "File \u001b[0;32m~/Documents/GitHub/crack_forecasting/.conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/GitHub/crack_forecasting/.conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/crack_forecasting/.conda/lib/python3.9/site-packages/geotorchai/models/grid/conv_lstm.py:75\u001b[0m, in \u001b[0;36mConvLSTM.forward\u001b[0;34m(self, input_tensor, hidden_state)\u001b[0m\n\u001b[1;32m     73\u001b[0m output_inner \u001b[39m=\u001b[39m []\n\u001b[1;32m     74\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(seq_len):\n\u001b[0;32m---> 75\u001b[0m     h, c \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcell_list[layer_idx](input_tensor\u001b[39m=\u001b[39;49mcur_layer_input[:, t, :, :, :], cur_state\u001b[39m=\u001b[39;49m[h, c])\n\u001b[1;32m     76\u001b[0m     output_inner\u001b[39m.\u001b[39mappend(h)\n\u001b[1;32m     78\u001b[0m layer_output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(output_inner, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/crack_forecasting/.conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/GitHub/crack_forecasting/.conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/crack_forecasting/.conda/lib/python3.9/site-packages/geotorchai/models/grid/conv_lstm.py:120\u001b[0m, in \u001b[0;36m_ConvLSTMCell.forward\u001b[0;34m(self, input_tensor, cur_state)\u001b[0m\n\u001b[1;32m    118\u001b[0m f \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msigmoid(cc_f)\n\u001b[1;32m    119\u001b[0m o \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msigmoid(cc_o)\n\u001b[0;32m--> 120\u001b[0m g \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtanh(cc_g)\n\u001b[1;32m    122\u001b[0m c_next \u001b[39m=\u001b[39m f \u001b[39m*\u001b[39m c_cur \u001b[39m+\u001b[39m i \u001b[39m*\u001b[39m g\n\u001b[1;32m    123\u001b[0m h_next \u001b[39m=\u001b[39m o \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mtanh(c_next)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 22.33 GB, other allocations: 13.89 GB, max allowed: 36.27 GB). Tried to allocate 64.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "# Pretrain the model on simple_line dataset\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        resize_dim = (1, 128, 128)\n",
    "        train_generator, test_generator, val_generator = load_data('../data/simple_line', resize=resize_dim)\n",
    "        set_model_name(f'convlstm_mse_epoch{epoch_nums}_lr{learning_rate}_pretraining')\n",
    "        createModelAndTrain(loss_mse, train_generator, test_generator, val_generator)\n",
    "        # createModelAndTrain(loss_fn=loss_ssim)\n",
    "        # createModelAndTrain(loss_fn=loss_phasefield)\n",
    "    finally:\n",
    "        # Clear the memory\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model directory: ../models/convlstm_mse_epoch40_lr0.002_w_pretraining\n",
      "Model directory for plots: ../models/convlstm_mse_epoch40_lr0.002_w_pretraining/plots\n",
      "Initial model checkpoint directory: ../models/convlstm_mse_epoch40_lr0.002_pretraining\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "createModelAndTrain() missing 3 required positional arguments: 'train_generator', 'test_generator', and 'val_generator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/jy/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb Cell 24\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jy/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb#X32sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     pretrained_model_dir \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../models/convlstm_mse_epoch40_lr0.002_pretraining\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jy/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb#X32sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     set_model_name(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mconvlstm_mse_epoch\u001b[39m\u001b[39m{\u001b[39;00mepoch_nums\u001b[39m}\u001b[39;00m\u001b[39m_lr\u001b[39m\u001b[39m{\u001b[39;00mlearning_rate\u001b[39m}\u001b[39;00m\u001b[39m_w_pretraining\u001b[39m\u001b[39m'\u001b[39m, initial_model_dir\u001b[39m=\u001b[39mpretrained_model_dir)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jy/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb#X32sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     createModelAndTrain(loss_fn\u001b[39m=\u001b[39;49mloss_mse, LOAD_INITIAL\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jy/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb#X32sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jy/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb#X32sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m# Clear the memory\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jy/Documents/GitHub/crack_forecasting/crack_forecasting/notebooks/3_Build_model.ipynb#X32sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n",
      "\u001b[0;31mTypeError\u001b[0m: createModelAndTrain() missing 3 required positional arguments: 'train_generator', 'test_generator', and 'val_generator'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        train_generator, test_generator, val_generator = load_data()\n",
    "        pretrained_model_dir = '../models/convlstm_mse_epoch40_lr0.002_pretraining'\n",
    "        set_model_name(f'convlstm_mse_epoch{epoch_nums}_lr{learning_rate}_w_pretraining', initial_model_dir=pretrained_model_dir)\n",
    "        createModelAndTrain(loss_mse, train_generator, test_generator, val_generator, LOAD_INITIAL=True)\n",
    "    finally:\n",
    "        # Clear the memory\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GeoTorchConvLSTM(\n",
       "  (lstm): ConvLSTM(\n",
       "    (cell_list): ModuleList(\n",
       "      (0): _ConvLSTMCell(\n",
       "        (conv): Conv2d(257, 1024, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      )\n",
       "      (1): _ConvLSTMCell(\n",
       "        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      )\n",
       "      (2): _ConvLSTMCell(\n",
       "        (conv): Conv2d(257, 4, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model from checkpoint file in models folder\n",
    "model = GeoTorchConvLSTM(input_dim, hidden_layer_sizes, num_layers)\n",
    "model.load_state_dict(torch.load(initial_checkpoint))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to use plt to show the model predictions\n",
    "def show_predictions(model, test_generator, device, num_samples=5):\n",
    "    model.eval()\n",
    "    for i, sample in enumerate(test_generator):\n",
    "        X_batch = sample[\"X_data\"].type(torch.FloatTensor).to(device)\n",
    "        Y_batch = sample[\"Y_data\"].type(torch.FloatTensor).to(device)\n",
    "\n",
    "        outputs = model(X_batch)\n",
    "\n",
    "        # TO-DO: fix the code here in case num_samples > batch_size\n",
    "        for j in range(num_samples):\n",
    "            try:\n",
    "                plt.figure(figsize=(8, 4))\n",
    "                plt.subplot(1, 2, 1)\n",
    "                plt.imshow(outputs[j, len_history - 1, 0, :, :].cpu().data.numpy(), cmap='gray')\n",
    "                plt.axis('off')\n",
    "                plt.title(\"Predicted\")\n",
    "                plt.subplot(1, 2, 2)\n",
    "                plt.imshow(np.squeeze(Y_batch[j, 0, :, :].cpu().data.numpy()), cmap='gray')\n",
    "                plt.axis('off')\n",
    "                plt.title(\"Ground Truth\")\n",
    "                plt.show()\n",
    "            except:\n",
    "                print(f\"sample {j} failed to plot\")\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions(model, test_generator, device, num_samples=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
